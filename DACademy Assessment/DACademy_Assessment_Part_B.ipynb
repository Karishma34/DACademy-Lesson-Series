{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxVBHva9v9ba"
      },
      "source": [
        "#DACademy Assessment Part B\n",
        "<p>This assessment is in two parts: Part A and Part B. You should answer\n",
        "ALL of question 1-15 in Part A and a coding assignment in Part B.</p> \n",
        "<p>Part A carries 30 marks, and the coding assignment, <b>Part B carries 70 marks.</b></p> \n",
        "<p>Upload your assessment as follows: DACademy Assessment Part B: 'your name'</p>\n",
        "<p>You are permitted to look through only python library websites and debugging website forums.</p> <p>All the best.</p>\n",
        "\n",
        "---\n",
        "\n",
        "<p> The dataset we will be working on today will be Tweets Sentiment Analysis on Omicron.</p>\n",
        "<p>Please download the csv file called 'omicron.csv' from the assessment page before starting this assessment.</p>\n",
        "<p><b>Note that the CSV file is placed in 'My Drive' of the Google Drive</b></p>\n",
        "<p>In this assessment, you will be asked to fill in the blanks in the cells wherever the codes are missing</p>\n",
        "<p>Listen to the instructions carefully and produce accurate answers per the instructions</p>\n",
        "<p>There will be a total of 30 questions worth 70 marks. \n",
        "<p>Try to attempt all questions.</p> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBjghRoh4Zsz"
      },
      "source": [
        "##Mount - *2 marks*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q1. Mount your google colab drive [2 marks]"
      ],
      "metadata": {
        "id": "5cbBLCgfqcWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW5jTyHCv5NN"
      },
      "outputs": [],
      "source": [
        "#Fill in the codes here...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7hmcTwe4x1i"
      },
      "source": [
        "##Import Libraries - *6 marks*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q2. Import the following libraries [6 marks]\n",
        "1. Libraries for dataframe (pandas)  \n",
        "2. Libraries for plotting data as data visualisations(seaborn, matplotlib etc.)\n",
        "3. Libraries for feature extraction(TfIdf, LabelBinarizer, train_test_split)\n",
        "4. Libraries for ML models: Multinomial Naive Bayes, Logistic Regression and svm \n",
        "5. Libraries used to measure metrics of models for evaluation:\n",
        "classification report, confusion matrix, accuracy score, Confusion Matrix Display\n",
        "6. Libraries to perform Hyper Parameter tuning: GridSearchCV"
      ],
      "metadata": {
        "id": "f2z7MV-nqt8A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4AmY62D4j0E"
      },
      "outputs": [],
      "source": [
        "#For dataframes\n",
        "# Fill in the code here...\n",
        "\n",
        "#Data visualisations\n",
        "%matplotlib inline\n",
        "# Fill in the code here...\n",
        "\n",
        "\n",
        "\n",
        "#For statistics\n",
        "import numpy as np\n",
        "#NLP Preprocessing\n",
        "!pip install pycountry\n",
        "import pycountry\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "# Word Cloud generation\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "#To get subjectivity and polarity, import textblob\n",
        "from textblob import TextBlob\n",
        "# Feature extraction\n",
        "# Fill in the code here...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ML Libraries\n",
        "# Fill in the code here...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Metrics\n",
        "# Fill in the code here...\n",
        "\n",
        "\n",
        "# Hyper parameter Tuning\n",
        "# Fill in the code here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suD2i6qt5pjU"
      },
      "source": [
        "##Loading Dataset - *2 marks*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Qn 3: Load your dataset using read_csv method in pandas and name your dataframe as: data_omicron [2 marks]"
      ],
      "metadata": {
        "id": "v-8PHbd9t087"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb392TVR5T9Y"
      },
      "outputs": [],
      "source": [
        "#Load the dataset using read_csv and name the dataframe as: data_omicron\n",
        "# Fill in the code here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE601iJD57rn"
      },
      "source": [
        "##Inspecting Dataset - *1 mark*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5U5WYsj6GyF"
      },
      "outputs": [],
      "source": [
        "data_omicron.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN15wLwo7E64"
      },
      "outputs": [],
      "source": [
        "data_omicron.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRuDMsUh7IYT"
      },
      "outputs": [],
      "source": [
        "data_omicron.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_ZxZ_A57O81"
      },
      "outputs": [],
      "source": [
        "#To print the total sum of null values\n",
        "data_omicron.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Qn4: Sum the number of null values using isnull and sum method [1 mark]"
      ],
      "metadata": {
        "id": "_5aYTmnCuE4A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6ax-BGx7V0M"
      },
      "outputs": [],
      "source": [
        "# Fill in the code...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCA2OkR7jHa"
      },
      "source": [
        "<b>So from a preliminary analysis of our data we can see that the train set contains 78168 rows and 16 columns. Our data contains about 3.6% of missing values with them being in 'user_location', 'user_description' and 'hashtags' columns. There are 6 numerical, 8 categorical and 2 boolean columns.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj3WcfkI7m61"
      },
      "source": [
        "##Exploratory Data Analysis - *12 marks*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbrq4ziz9IWe"
      },
      "source": [
        "###Data Visualisation - Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBh36X8R-3s5"
      },
      "source": [
        "####Displot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Q5: \n",
        "1. Set the figure size to (20,15 using plt.figure) [1 mark]\n",
        "2. Set palette of displot to flare [1 mark]\n",
        "3. Set title to 'Bar plot showing Missing Values in training data' with bold text of size: 25 and the color to brown [2 marks]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s_742F51EBqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8WEzLXD7blF"
      },
      "outputs": [],
      "source": [
        "# Fill in the code here...\n",
        "\n",
        "sns.displot(\n",
        "    data=data_omicron.isna().melt(value_name=\"missing\"),\n",
        "    y=\"variable\",\n",
        "    hue=\"missing\",\n",
        "    multiple=\"fill\",\n",
        "    aspect=3,\n",
        "    # Fill in the code here...\n",
        "\n",
        ")\n",
        "# Fill in the code here...\n",
        "plt.xlabel(\" \")\n",
        "plt.ylabel(\" \")\n",
        "plt.xticks(size = 12, weight = 'bold', color = 'black')\n",
        "plt.yticks(size = 12, weight = 'bold', color = 'black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csTdF2ek_uW1"
      },
      "source": [
        "####Correlation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Q6: Plot a heatmap and set the colormap to BuPu [2 marks]"
      ],
      "metadata": {
        "id": "Mk4sRL9SIq3x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EQguxhS_hzH"
      },
      "outputs": [],
      "source": [
        "# Fill in the code here...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIUMxX52_3ti"
      },
      "source": [
        "<b>From this we can see that favourites and retweets are highly correlated. user_verified and user_followers also have a high correlation.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhZFo7jiDPih"
      },
      "source": [
        "#### Location - Data Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Q7: Print out the first 5 countries of the list column: country_name [1 mark]\n",
        "\n"
      ],
      "metadata": {
        "id": "qoto_NyJJ6af"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXuEwRGcCn9W"
      },
      "outputs": [],
      "source": [
        "# Excluding null values (where location is not specified) in user_location \n",
        "location = [loc for loc in data_omicron['user_location'] if type(loc)==str]\n",
        "\n",
        "# Extracting country names from given location\n",
        "country_name = [country.name for loc in location for country in pycountry.countries if country.name in loc]\n",
        "# Fill in the code here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Q8: Plot a barplot with these conditions set: [5 marks]\n",
        "1. Figure size (20,8)\n",
        "2. size: xx-large\n",
        "3. Plot of Country vs Tweet Count where palette is set to 'hls'\n",
        "<p>Hint: x = 'Country', y = 'Tweets Count' in df_country dataframe</p>"
      ],
      "metadata": {
        "id": "PmxcyDqQM0mX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLNRS4ZoDibQ"
      },
      "outputs": [],
      "source": [
        "# Dictionary to count the number of occurances of each country\n",
        "count={}\n",
        "for country in country_name:\n",
        "    count[country] = count.get(country, 0) + 1\n",
        "\n",
        "# Country vs tweets count\n",
        "df_country = pd.DataFrame({'Country': list(count.keys()),'Tweets Count': list(count.values())})\n",
        "df_country = df_country.sort_values(by = 'Tweets Count', ascending=False)#In descending order\n",
        "df_country = df_country[:10] # top 10 countries\n",
        "\n",
        "# Plot the data\n",
        "# Fill in the code here...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwYbkpugRaTZ"
      },
      "source": [
        "##Data Preprocessing - *18 marks*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNIgKjV7Rdsp"
      },
      "source": [
        "###Tweet Preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Q9: Setting lemmatizer method from its library to the lemmatizer variable [1 mark]"
      ],
      "metadata": {
        "id": "PTrMKiiPOjWj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrbhbQqT1JiP"
      },
      "outputs": [],
      "source": [
        "# Setting lemmatizer variable\n",
        "# Fill in the codes here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Q10: Setting the stopword list to english (Note: Set the variable of this list to stopword)\n",
        "<h4>[1 mark]</h4>"
      ],
      "metadata": {
        "id": "wDO1ydAPOroh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the codes here..."
      ],
      "metadata": {
        "id": "bK8AgL66O5JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Q11. Fill the missing removal within the tweet_processor [7 marks]\n",
        "\n",
        "1. Removing new lines with replace\n",
        "2. Change all text to lowercase using lower() function\n",
        "3. Perform lemmatisation \n",
        "4. Remove stopwords\n",
        "5. Replace all words, 'covid19' with 'covid'"
      ],
      "metadata": {
        "id": "5YKBc_YEPWAy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpfzBcpiPB4f"
      },
      "outputs": [],
      "source": [
        "# Preprocess text\n",
        "def tweet_processor(text):\n",
        "    \n",
        "    # Remove new lines\n",
        "    # Fill in the codes here...\n",
        "    \n",
        "    # Remove links\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    \n",
        "    # Remove hashtags at the end of text\n",
        "    text = re.sub('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', '',text)\n",
        "    \n",
        "    # Remove handles\n",
        "    text = re.sub('@[\\w]+', '',text)\n",
        "    \n",
        "    # Remove punctuations\n",
        "    punc ='''.?!,:;-_â€”[](){}'\"`~|\\/@#$%^&+=*'''\n",
        "    for i in text:\n",
        "        if i in punc:\n",
        "            text = text.replace(i, '') \n",
        "    \n",
        "    # Remove extra spaces\n",
        "    re.sub(\"\\s\\s+\", \" \", text)\n",
        "    \n",
        "    # Lower case\n",
        "    # Fill in the codes here...\n",
        "    \n",
        "    \n",
        "    # Lemmatization\n",
        "    # Fill in the codes here...\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    # Stopword removal\n",
        "    # Fill in the codes here...\n",
        "\n",
        "\n",
        "    \n",
        "    # Replace covid19 with covid\n",
        "    # Fill in the codes here...\n",
        "\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Remove promotional tweets (with words 'subscribe' and 'subscription')\n",
        "def no_spam(text):\n",
        "    if 'subscri' in text:\n",
        "        text=''\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Qn 12: Apply the tweet_processor function to the column, 'text' in dataframe, 'data_omicron' \n",
        "####[1 mark]"
      ],
      "metadata": {
        "id": "uMb-DExWRhqP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-cStp8vRoFL"
      },
      "outputs": [],
      "source": [
        "# Applying tweet processor\n",
        "# Fill in the code here...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogtjIyErXD-_",
        "outputId": "5f2817c3-c50d-48ac-9a24-c06048e8ce40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        told id back omicron â€œodium medicum insensate ...\n",
              "1                                     someone told october\n",
              "2        glad see public schoolkids wrapping 2021 sign ...\n",
              "3        automation system become increasingly complex ...\n",
              "4        ðŸŸ¢ u think omicron fud longðŸ“ˆ ðŸ”´ u think omicron ...\n",
              "                               ...                        \n",
              "78163    growth 7d u confirmed covid case county mt   2...\n",
              "78164    elek ticker symbol big big green ev car winner...\n",
              "78165    yep everyone almost omicron wa vaccinated son ...\n",
              "78166    elek ticker symbol big big green ev car winner...\n",
              "78167    american get sicker omicron stall everything h...\n",
              "Name: text, Length: 78168, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "data_omicron['text'] "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Qn 13: Apply the demoji function to the column, 'text' in the dataframe, 'data_omicron' \n",
        "####[1 mark]"
      ],
      "metadata": {
        "id": "1YCvVQHER37Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C8gWHDw2AoJ"
      },
      "outputs": [],
      "source": [
        "# Demoji function\n",
        "def demoji(text):\n",
        "    \n",
        "    # Frequent emojis whhich will be kept\n",
        "    pattern = 'ðŸ˜¤|ðŸ˜¡|ðŸ˜ |ðŸ˜‘|ðŸ™„|ðŸ¤¨|ðŸ˜¶|ðŸ˜±|ðŸ™€|ðŸ˜²|ðŸ˜“|ðŸ˜°|ðŸ˜¢|ðŸ˜¥|ðŸ˜­|ðŸ˜ª|ðŸ¤•|ðŸ˜”|ðŸ˜£|ðŸ™|ðŸ˜’|ðŸ˜–|ðŸ˜•|ðŸ¥´|ðŸ¤’|â˜¹ï¸|ðŸ˜ž|ðŸ˜·|ðŸ¤§|ðŸ˜§|ðŸ˜¨|ðŸ˜©|ðŸ¥º|ðŸ˜¦|ðŸ˜†|ðŸ˜€|ðŸ¤­|ðŸ¤©|ðŸ˜Œ|ðŸ¥°|ðŸ˜|ðŸ˜˜|ðŸ˜‚|ðŸ˜…|ðŸ˜Š|ðŸ˜|ðŸ˜™|ðŸ˜‡'\n",
        "    for word in text:    \n",
        "        if re.match(pattern, word):\n",
        "            continue\n",
        "            \n",
        "        # Remove all other non ascii characters\n",
        "        text=text.replace(word, re.sub('[^\\x00-\\x7f]','', word)).strip()\n",
        "        \n",
        "    return text\n",
        "\n",
        "# Apply function\n",
        "# Fill in the codes here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Qn 14: Apply the convert function to the column, 'text' in the dataframe, 'data_omicron' and set it to a new column within the dataframe and name it 'senti_text'\n",
        "####[2 marks]"
      ],
      "metadata": {
        "id": "KTz1_EWZSYNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ME3Fhs2LY6"
      },
      "outputs": [],
      "source": [
        "# Convert funtion\n",
        "def convert(text):\n",
        "    \n",
        "    # Dictionary of emoji with their meaning\n",
        "    d = {'ðŸ˜¤':'frustrated','ðŸ˜¡':'angry','ðŸ˜ ':'angry','ðŸ˜±':'horrified','ðŸ™€':'shock','ðŸ˜²':'shock','ðŸ™„':'disapproval','ðŸ¤¨':'suspicion',\n",
        "         'ðŸ˜¶':'disappointment','ðŸ˜“':'sad','ðŸ˜°':'sad','ðŸ˜¢':'sad','ðŸ˜¥':'sad','ðŸ˜­':'sad','ðŸ˜ª':'sad','ðŸ¤•':'sad','ðŸ˜”':'sad','ðŸ˜£':'sad','ðŸ™':'sad',\n",
        "         'ðŸ˜’':'sad','ðŸ˜–':'sad','ðŸ˜•':'sad','ðŸ¥´':'sad','ðŸ¤’':'sad','â˜¹ï¸':'sad','ðŸ˜ž':'sad','ðŸ˜·':'sick','ðŸ¤§':'sick','ðŸ˜§':'sad','ðŸ˜¨':'sad',\n",
        "         'ðŸ˜©':'sad','ðŸ¥º':'sad','ðŸ˜¦':'sad','ðŸ˜«':'sad','ðŸ˜†':'happy','ðŸ˜€':'smile','ðŸ¤­':'embarrassment','ðŸ¤©':'exciting','ðŸ¥°':'affection',\n",
        "         'ðŸ˜':'smile','ðŸ˜‚':'laugh','ðŸ˜…':'nervousness','ðŸ˜Š':'smile','ðŸ˜':'fun','ðŸ˜™':'affection','ðŸ˜‡':'blessed'}\n",
        "    \n",
        "    for emoji, sentiment in d.items():\n",
        "        text=text.replace(emoji, sentiment)\n",
        "    return text\n",
        "\n",
        "# Apply function\n",
        "# Fill in the codes here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANe2LgNj2Vml"
      },
      "source": [
        "###Word Cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Qn 15: Generate the Word Cloud by following these steps\n",
        "####[5 marks]\n",
        "1. Set figure size to width 12 and height 8 pixels\n",
        "2. Use imshow method to show the word cloud generated where interpolation is set as bilinear\n",
        "3. There should be no axis\n",
        "4. Print the title as: 'Omicron Tweets Word Cloud' where size is set to 'x-large'\n",
        "5. Save the image as a jpg file as 'omicron.jpg' with dpi set to 720"
      ],
      "metadata": {
        "id": "bw4Mx1mKTgt5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx61HjRr2YE_"
      },
      "outputs": [],
      "source": [
        "# Creating the text variable\n",
        "text = \" \".join(tweet for tweet in data_omicron.senti_text)\n",
        "\n",
        "# Creating word_cloud with text as argument in .generate() method\n",
        "word_cloud = WordCloud(collocations=False, background_color='white',\n",
        "                       max_words=50, stopwords=STOPWORDS, min_word_length=4,\n",
        "                       width=2048, height=1080).generate(text)\n",
        "\n",
        "# Display the generated Word Cloud\n",
        "# Fill in the codes here...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfy_rnz12sLD"
      },
      "source": [
        "###No. of words in the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8vrCqli2vfw"
      },
      "outputs": [],
      "source": [
        "# Word count\n",
        "word_count = [len(text.split()) for text in data_omicron.senti_text]\n",
        "data_omicron['word_count'] = word_count\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15,7))\n",
        "ax=sns.histplot(x='word_count', data=data_omicron, bins=20, color='#00acee')\n",
        "plt.title('Number of words in text',size='xx-large')\n",
        "plt.xlabel('No:of words')\n",
        "plt.ylabel('No:of tweets')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N41dfbPBXFTI"
      },
      "outputs": [],
      "source": [
        "word_count = [len(text.split()) for text in data_omicron.senti_text]\n",
        "data_omicron['word_count'] = word_count\n",
        "\n",
        "# Excluding text with less than 3 words\n",
        "data_omicron=data_omicron[data_omicron['word_count']>2]\n",
        "\n",
        "# Excluding tweets with more than 16 words\n",
        "data_omicron=data_omicron[data_omicron['word_count']<17]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3fZnehi28TJ"
      },
      "source": [
        "##Sentiment Analysis - *9 marks*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Qn 16: Create a function to get subjectivity of text data using TextBlob\n",
        "###[2 marks]"
      ],
      "metadata": {
        "id": "Gv4VwBBaVEzz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jh2KOfN6OaH"
      },
      "outputs": [],
      "source": [
        "# Subjectivity of the processed data\n",
        "# Create a function to get the subjectivity\n",
        "# Fill in the codes here...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Qn 17: Create a function to get polarity of text data using TextBlob\n",
        "###[2 marks]"
      ],
      "metadata": {
        "id": "LCEfbIGAVX6f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc7daI6L6RBi"
      },
      "outputs": [],
      "source": [
        "# Polarity of the processed data\n",
        "# Create a function to get the polarity\n",
        "# Fill in the codes here...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1G24u0j6TTt"
      },
      "outputs": [],
      "source": [
        "# Creating columns to display subjectivity and polarity\n",
        "data_omicron['Subjectivity'] = data_omicron['senti_text'].apply(getSubjectivity)\n",
        "data_omicron['Polarity'] = data_omicron['senti_text'].apply(getPolarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Qn 18: Create a function called getComputation to assign if the text is 'Negative', 'Neutral' or 'Positive' using the polarity score in 'Polarity' column\n",
        "###[3 marks] \n",
        "###Qn 19: Apply this function to data_omicron dataframe and create a new column, 'Computation_Analysis' to store it\n",
        "###[2 marks]"
      ],
      "metadata": {
        "id": "u3ltRiB8V8h3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoJikqTl55kd"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1OWXFnj6E9t"
      },
      "outputs": [],
      "source": [
        "# Creating a new dataframe sort_data to sort te polarity amd computation analysis\n",
        "data_omicron_sort = data_omicron.sort_values(by=['Polarity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFqyfj6hicW4"
      },
      "outputs": [],
      "source": [
        "data_omicron_sort.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3P786iAWKOF"
      },
      "source": [
        "##Measuring Baseline performance - *20 marks*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-6dF2YtWQr5"
      },
      "source": [
        "###Multinomial Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw4KvltEWWib"
      },
      "source": [
        "####Vectorising Training Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljn70lnmXJ94"
      },
      "source": [
        "#####Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Qn 20: Set tfidf vectorizer class from the library to the tfidf variable\n",
        "######[1 mark]"
      ],
      "metadata": {
        "id": "ezF4ABr9XdBV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiPsJn2UWPr0"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaLqkecHWo7a"
      },
      "outputs": [],
      "source": [
        "tweet_text = tfidf.fit_transform(data_omicron_sort['senti_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRWoNFvvW9IN"
      },
      "outputs": [],
      "source": [
        "tfidf.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Qn 21: Print the shape of the tweet_text\n",
        "######[1 mark]"
      ],
      "metadata": {
        "id": "7hqQIMq4X1dg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Rh3rABXCNA"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5R0YMuXHXX"
      },
      "source": [
        "#####Target extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Qn 22: Set label binarizer class from the library to the target_lb variable\n",
        "######[1 mark]"
      ],
      "metadata": {
        "id": "zUMethyyYoWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4taDvuwXB-Y"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hohMNdgXXgpY"
      },
      "outputs": [],
      "source": [
        "targets=target_lb.fit_transform(data_omicron_sort['Computation_Analysis'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Qn 23: Print the shape of the targets \n",
        "######[1 mark]"
      ],
      "metadata": {
        "id": "bdBEPIy_Yz85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhTvw6z1lkIm"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmLLvPrx2VuC"
      },
      "outputs": [],
      "source": [
        "target_labels = np.argmax(targets, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfll-RtIbjmc"
      },
      "source": [
        "####Training model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Qn 24: \n",
        "#####Split the feature: tweet_text and the target: target_labels with train:test ratio as 80:20 \n",
        "#####[3 marks]\n",
        "#####The variables for the train and test sets should be:\n",
        "1. X_train\n",
        "2. y_train\n",
        "3. X_test\n",
        "4. y_test\n"
      ],
      "metadata": {
        "id": "Xy8eQDmNZJm7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJsLxshGat3l"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Qn 25: Set the Multinomial Naive Bayes model class to a variable called mnb and fit x and y train values\n",
        "#####[2 marks]"
      ],
      "metadata": {
        "id": "2B9MRuDFZ8HI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zy6HBpfcB62"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Qn 26: Predict the y values using the predict method and name the variable for the predict values as 'mnb_tfidf_predict'. Print out the predict value\n",
        "#####[2 marks]"
      ],
      "metadata": {
        "id": "J2wiEwQUakxC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXq8QEjDcbv7"
      },
      "outputs": [],
      "source": [
        "# Predicting the model for tfidf features\n",
        "# Fill in the codes here...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Qn 27: Calculate the accuracy score using the accuracy score metric and name it as 'mnb_acc_score'. Print out the accuracy score in percentage form as 2 decimal places\n",
        "#####[2 marks]"
      ],
      "metadata": {
        "id": "waQgm1N-bNb0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ax2fWJ117C"
      },
      "outputs": [],
      "source": [
        "# Accuracy score \n",
        "# Fill in the codes here...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Qn 28: Plot out the confusion matrix for this model. \n",
        "#####[3 marks]\n",
        "1. Name the confusion matrix with the variable, cm_mnb\n",
        "2. Name the display for confusion matrix as disp\n",
        "3. Plot the disp\n"
      ],
      "metadata": {
        "id": "8ndjB-TBeIm6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdj60jiA2BIa"
      },
      "outputs": [],
      "source": [
        "# Fill in the codes here...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzE04HUS-rxb"
      },
      "source": [
        "###Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOcdSNtZ-xR1"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"gamma\": [0.1, 1.0, 10, 100],\n",
        "    \"C\": [0.1, 1.0, 10, 100]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9WHTqMb-6Z4"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(SVC(), param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WvMacPi-9in"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Qn 29: Find the best parameter using .best_params_ and print it\n",
        "####[2 marks]"
      ],
      "metadata": {
        "id": "FcLfRgD1cUqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the codes here...\n"
      ],
      "metadata": {
        "id": "jc7h9N_5pvSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting target based on test feature\n",
        "y_pred = grid_search.predict(X_test)"
      ],
      "metadata": {
        "id": "jsruIrwSp6Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoiUGeSh_nGz"
      },
      "outputs": [],
      "source": [
        "grid_search.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Accuracy\n",
        "svm_param_acc = accuracy_score(y_pred, y_test)\n",
        "print(\"Test accuracy: {:2f}%\".format(svm_param_acc*100))"
      ],
      "metadata": {
        "id": "q1kaixaNqBPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Qn 30: Print the confusion matrix and classification report for the tuned model, SVC\n",
        "####[2 marks]"
      ],
      "metadata": {
        "id": "qHQ9nQnDchvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the codes here...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ow11wJxFqJSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZxVBHva9v9ba",
        "uBjghRoh4Zsz",
        "U7hmcTwe4x1i",
        "f2z7MV-nqt8A",
        "suD2i6qt5pjU",
        "v-8PHbd9t087",
        "aE601iJD57rn",
        "_5aYTmnCuE4A",
        "oj3WcfkI7m61",
        "Kbrq4ziz9IWe",
        "s_742F51EBqO",
        "csTdF2ek_uW1",
        "Mk4sRL9SIq3x",
        "ZhZFo7jiDPih",
        "qoto_NyJJ6af",
        "PmxcyDqQM0mX",
        "HwYbkpugRaTZ",
        "qNIgKjV7Rdsp",
        "PTrMKiiPOjWj",
        "wDO1ydAPOroh",
        "I3fZnehi28TJ",
        "Gv4VwBBaVEzz",
        "LCEfbIGAVX6f",
        "u3ltRiB8V8h3",
        "e3P786iAWKOF",
        "2-6dF2YtWQr5",
        "Vw4KvltEWWib",
        "ezF4ABr9XdBV",
        "7hqQIMq4X1dg",
        "fC5R0YMuXHXX",
        "zUMethyyYoWO",
        "bdBEPIy_Yz85",
        "kfll-RtIbjmc",
        "Xy8eQDmNZJm7",
        "2B9MRuDFZ8HI",
        "J2wiEwQUakxC",
        "waQgm1N-bNb0",
        "8ndjB-TBeIm6",
        "DzE04HUS-rxb",
        "sZ2E2J_f45Rp",
        "iUxJbEZK7Xuy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}